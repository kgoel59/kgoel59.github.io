<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="572CpV_LTBRfv5HZ0v-VN2J6r6cZE--b8udH0_fg1Jo"> <meta name="msvalidate.01" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> CSCI935 - Computer Vision Algorithms and Systems | Karan Goel </title> <meta name="author" content="Karan Goel"> <meta name="description" content="My Learning on CSCI935"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?acbd3e65a6723e88b5535b00becb6b4d"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://karangoel59.com/blog/2024/computer-vision/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?bf50d6d9dd867d3e0f3b0add94449649"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Karan </span> Goel </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">CSCI935 - Computer Vision Algorithms and Systems</h1> <p class="post-meta"> July 05, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/projects"> <i class="fa-solid fa-hashtag fa-sm"></i> projects</a>   <a href="/blog/tag/learning"> <i class="fa-solid fa-hashtag fa-sm"></i> learning</a>   <a href="/blog/tag/uow"> <i class="fa-solid fa-hashtag fa-sm"></i> uow</a>     ·   <a href="/blog/category/learning"> <i class="fa-solid fa-tag fa-sm"></i> learning</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h3 id="my-learning-from-computer-vision-algorithms">My Learning from Computer Vision Algorithms</h3> <p>As I progress through my journey in the Computer Vision Algorithms subject, I’ve come to appreciate the intricate details that shape how machines perceive and interpret visual data. This subject has offered me a comprehensive understanding of how light, color, and various algorithms work together to enable computers to perform tasks that once seemed exclusive to human vision. Here’s a breakdown of some key concepts and techniques I’ve learned:</p> <h4 id="understanding-light-and-color"><strong>Understanding Light and Color</strong></h4> <p>Light is more than what we see; it’s electromagnetic radiation that interacts with our eyes, triggering processes that result in color perception. Human eyes contain rods for low-light vision and cones that detect color. The cones come in three types, each responding to different wavelengths of light, forming the basis of the <strong>tristimulus theory</strong>. This theory suggests that any color can be represented using three values corresponding to red, green, and blue (RGB). This understanding is crucial in computer vision, where <strong>color models</strong> like RGB, CIE XYZ, and CIELab are fundamental to image processing.</p> <h4 id="the-mechanics-of-image-sensors"><strong>The Mechanics of Image Sensors</strong></h4> <p>In exploring how images are captured, I learned about <strong>image sensors</strong> like CMOS and CCD, which convert light into electric charges and then into digitized image samples. This digitization process involves converting continuous signals into quantized samples, with proper sampling rates essential to avoid aliasing.</p> <p>Digital cameras use <strong>color filter arrays (CFA)</strong> to capture accurate color information by representing the real world through three color channels—red, green, and blue. <strong>Gamma correction</strong> maps these quantized samples into a domain that our eyes perceive as uniform, enhancing digital image quality.</p> <h4 id="the-concept-of-machine-vision"><strong>The Concept of Machine Vision</strong></h4> <p><strong>Machine vision</strong> involves a multistage process where each stage influences the next. This concept highlights the importance of <strong>image enhancement</strong> to make images suitable for specific applications. However, image capture often introduces <strong>distortions</strong> that degrade quality, requiring quantitative metrics to ensure accuracy.</p> <p><img src="/assets/img/T3-Image-Quality-and-Enhancement-pdf.png" alt="Machine Vision" width="500"></p> <p><strong>Noise</strong> is a challenge in digital imaging, arising from the analog components in cameras. It requires statistical methods for reduction to preserve useful information.</p> <h4 id="edge-detection-and-keypoint-detection"><strong>Edge Detection and Keypoint Detection</strong></h4> <p>Edge detection is vital in computer vision, as edges indicate boundaries and shapes. <strong>Gradient calculation</strong> detects these discontinuities in images. However, noise can affect edge detection, necessitating noise reduction techniques.</p> <p>The <strong>Canny edge detector</strong> is a robust method combining edge detection, thinning, tracing, and linking to produce clean edges. <strong>Keypoint detection</strong> follows, using algorithms like the <strong>Harris Corner Detector</strong> to identify points of interest in an image. The Harris Detector’s mathematical foundation, including eigenvalue analysis, ensures reliable keypoint detection.</p> <h4 id="advanced-techniques-sift-and-hough-transform"><strong>Advanced Techniques: SIFT and Hough Transform</strong></h4> <p>The <strong>SIFT (Scale-Invariant Feature Transform)</strong> algorithm is crucial for detecting, localizing, and describing keypoints, enabling robust object recognition across varying scales and orientations.</p> <p>The <strong>Hough transform</strong> locates shapes like lines and circles within an image. It converts the image into a binary edge map, generates shape parameters for each edge point, and accumulates these parameters in an array representing the parameter space. Peaks in this array correspond to likely shapes, facilitating shape localization.</p> <h4 id="segmentation-and-object-detection"><strong>Segmentation and Object Detection</strong></h4> <p><strong>Segmentation</strong> is essential for object detection, involving methods like clustering-based approaches, thresholding, and <strong>K-means clustering</strong>. Advanced techniques like <strong>mean shift clustering</strong> and <strong>normalized cuts (NCut)</strong> provide more precise segmentation in complex scenes.</p> <p><strong>Object detection</strong> involves identifying and localizing objects within images. Techniques such as <strong>face detection</strong> and <strong>pedestrian detection</strong> use specific features and classifiers to recognize and categorize objects, crucial for applications like surveillance and autonomous driving.</p> <h4 id="motion-estimation-and-optical-flow"><strong>Motion Estimation and Optical Flow</strong></h4> <p><strong>Motion estimation</strong> determines the movement of objects within image sequences. <strong>Optical flow</strong> calculates the apparent motion of brightness patterns across frames. Techniques like <strong>Horn and Schunck</strong> and <strong>Lucas and Kanade</strong> methods estimate optical flow, each offering different approaches to handling motion.</p> <h3 id="what-i-found-most-interesting-while-learning-about-computer-vision-algorithms">What I Found Most Interesting While Learning About Computer Vision Algorithms</h3> <p>Studying computer vision algorithms has been enlightening, revealing fascinating aspects of technology and human perception. Key points of appreciation include:</p> <h4 id="1-the-intricacies-of-human-vision"><strong>1. The Intricacies of Human Vision</strong></h4> <p>The complexity and capability of human vision are remarkable. I was amazed to learn that our eyes can perceive a spectrum of colors that digital devices cannot fully reproduce. The CIE 1931 color space models human color perception, highlighting the sophistication of our visual system compared to technology.</p> <h4 id="2-the-mathematical-foundations-of-computer-vision"><strong>2. The Mathematical Foundations of Computer Vision</strong></h4> <p>The extensive mathematical framework underlying computer vision is intriguing. Concepts like Gaussian distributions, the Central Limit Theorem, and the Fourier Transform illustrate how images can be analyzed as signals through mathematical lenses. This approach connects computer vision to broader areas of signal processing and applied mathematics.</p> <h3 id="what-i-dont-like">What I Don’t Like</h3> <p>While foundational formulas and algorithms are crucial, many have become somewhat redundant with the rise of deep learning and Convolutional Neural Networks (CNNs). Modern approaches have simplified and automated tasks that were once complex and algorithm-intensive. Consequently, some traditional methods and mathematical formulations have become less prominent, shifting the focus toward leveraging deep learning models for advanced and efficient image processing.</p> <h3 id="overall-experience">Overall Experience</h3> <p>I achieved a Distinction in the course. I feel significantly more knowledgeable about computer vision than before and am eager to apply this knowledge in practice.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/machine-learning/">CSCI933 - Machine Learning Algorithms and Applications</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/absa/">Building an Aspect Based Sentiment Analysis System</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/dev-env/">Unveiling My Unique Dev Environment</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/myfirstproposal/">First Research Proposal</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/project_management/">Hills and Valleys of Project Management: An Insightful Journey</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Karan Goel. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: August 11, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script type="text/javascript">$(function(){$('[data-toggle="tooltip"]').tooltip()});</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-M3ERZCHGHH"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-M3ERZCHGHH");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>